## 0. 背景

在 Transfer Learning 中，**选择正交性高的数据集**可显著提升目标任务表现。例如，MultiNLI上pretrain过的BERT，在Boolq上能取得0.804 acc（from 0.62 majority baseline），作者认为“This suggests MultiNLI contains signal orthogonal to what is found in BERT’s unsupervised objectives.”。然而，如何 **系统地判断数据集之间的正交性** 仍缺乏标准方法。

## 1. 实验
MultiNLI/Boolq BERT实验等待⌛️中

训练参数：
use a batch size of 24, learning rate of 1e-5, and 5 training epochs for BERT

参考链接：
- paper：BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Question
- dataset：https://github.com/google-research-datasets/boolean-questions 
- code：https://github.com/google-research/language/tree/master/language/boolq 

## 2.概念
正交性（Orthogonality）：源数据集提供的信息与目标任务互补，在表示空间中新增“非冗余维度”，可增强下游表现。

我的理解：
- MultiNLI（自然语言推理数据库）对于Boolq是正交，因为提供了判断true/false的“推理能力”；
- 但是Pubmed（医学 等Domain Specific数据集）和Boolq（娱乐/自然/运动/..百科类数据集）不算正交，反而引入了“冗余维度”

相似概念区分：迁移性（transferability）
在源任务上 fine-tune 预训练模型 ➔ 再在目标任务上 fine-tune ➔ 相比直接在目标任务 fine-tune，performance gain 的程度。相较于正交性先验地判断，迁移性后验地评估了源任务对目标任务表现提升的帮助大小

但是我想知道“能够先验地判断一个数据集是否orthogonality，从而是否能够用于transfer learning acc提升”？

## 3.思路
我目前的思路分为以下四个方面：

|     | **方法**                                        | **作用**                        | **阶段** |
| --- | --------------------------------------------- | ----------------------------- | ------ |
| 1   | **Zero-shot performance**                     | 先验判断模型是否已 encode 数据集信息        | 先验     |
| 2   | **distribution similarity**                   | 判断数据集 feature distribution 差异 | 先验     |
| 3   | **Anisotropy / Intrinsic Dimension dynamics** | 测量训练中表征变化，量化“注入的新信息维度”        | 后验     |
| 4   | **最终验证**                                      | 是否提升目标任务表现（受调参影响）             | 后验     |

1，zero-shot probing
无脑跑一遍validation，低时间成本，低代码量，
如果acc高 在这个数据集上的表现已经够高（可排除该数据集作为上游数据集带来的训练增益？）
==如果acc低并不能区分是由于单纯的领域不同，还是更深层的推理能力等问题==

2，判断数据集的相似性
吃主观经验，需细读dataset profile，对领域/提法/数据分布等有基本认知；
有大量带有特征工程色彩的量化方法，但问题是即使能够精确计算这些数值，==并不构成正交性的充分条件==
方法很多，简单列举：

| **方法**                                 | **作用**                     | **局限**                  |
| -------------------------------------- | -------------------------- | ----------------------- |
| **KL divergence / Wasserstein**        | 量化 distribution difference | 与正交性非充分条件               |
| **Task Embedding Distance (Task2Vec)** | 量化任务表示相似性                  | 需要 FIM 计算，复杂            |
| **Mutual Information**                 | 理论上最直接衡量信息 overlap         | label space alignment 难 |
|                                        |                            |                         |

3，各向异性Anisotropy
更直接/根本，度量模型训练过程中的实际表征变化；但是只是作为后验解释性的存在
缺点：后验，训练耗时

4，最终验证
最直接，但也可能受到finetune技巧影响；
或有常见数据库研究可查表，见todo

## 4.TODO
有待验证的是：
1，如实验1描述的，以multiNLI为上游的pretrain是否能对下游的boolq带来近20%的增益（即使在原论文并未提供pretrain参数细节，无法完全复现的情况下）

2，关于这个逻辑的验证：“如果 probing acc 低，且 distribution similarity 中等 ➔ 很可能是“正交性高”的好 candidate。“
关于“中等”又包含了以下假设“如果 distribution gap 太大，模型无法有效 generalize（domain mismatch problem）；如果 distribution 几乎一致，模型已 encode，无需 transfer（redundant）”

3，Taskonomy：正交性和迁移性
transferability：https://aclanthology.org/2020.emnlp-main.635.pdf，
文章的观点是：“任务在 TASKEMB 空间相似 ➔ **几乎可以保证 transferability**”，
言下之意TASKEMB是比TEXTEMB更本质的特征，这和“multiNLI做pretrain能增加Boolq表现”结论一致。
但是如果可以通过查表常见数据集，transferability可以变成先验，可归入思路2


---

[1] Clark, Christopher, et al. "Boolq: Exploring the surprising difficulty of natural yes/no questions." _arXiv preprint arXiv:1905.10044_ (2019).
[2] Vu, Tu, et al. "Exploring and predicting transferability across NLP tasks." _arXiv preprint arXiv:2005.00770_ (2020).